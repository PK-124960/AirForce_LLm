{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73c21e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Extracted 22 pages.\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import json\n",
    "\n",
    "pdf_path = \"AFTERBURNER CONTROL_Chapter 3.pdf\"\n",
    "doc = fitz.open(pdf_path)\n",
    "\n",
    "page_data = []\n",
    "\n",
    "for i in range(len(doc)):\n",
    "    text = doc[i].get_text()\n",
    "    page_data.append({\n",
    "        \"page\": i + 1,\n",
    "        \"text\": text\n",
    "    })\n",
    "\n",
    "# save as JSON\n",
    "with open(\"extracted_text.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(page_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"‚úÖ Extracted {len(page_data)} pages.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da65158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Total chunks: 82\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from langchain.schema import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Load JSON dataset\n",
    "with open(\"extracted_text.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    pages = json.load(f)\n",
    "\n",
    "# define chunks \n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 500,\n",
    "    chunk_overlap = 50\n",
    ")\n",
    "\n",
    "docs = []\n",
    "for p in pages:\n",
    "    chunks = text_splitter.split_text(p[\"text\"])\n",
    "    for chunk in chunks:\n",
    "        doc = Document(\n",
    "            page_content=chunk,\n",
    "            metadata={\"page\": p[\"page\"]}\n",
    "        )\n",
    "        docs.append(doc)\n",
    "\n",
    "print(f\"‚úÖ Total chunks: {len(docs)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5bca6d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_48272\\3419486862.py:5: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceEmbeddings(\n",
      "d:\\AirForce_project\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ FAISS vectorstore saved.\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# multilingual model for Thai\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
    ")\n",
    "\n",
    "# FAISS index: Facebook AI Similarity Search\n",
    "db = FAISS.from_documents(docs, embedding_model)\n",
    "\n",
    "\n",
    "db.save_local(\"faiss_afterburner_index\")\n",
    "\n",
    "print(\"‚úÖ FAISS vectorstore saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41b23310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîé Chunk 1 (‡∏´‡∏ô‡πâ‡∏≤ 15):\n",
      "Remove bypass valve (11) and insert (9) only if\n",
      "screw (84) and preformed packings (86, 87). Break away\n",
      "clogged or damaged. Remove standpipe (14)\n",
      "torque shall be 2.0 pound-inch minimum when removing\n",
      "and insert (15) only if damaged. Breakaway\n",
      "linkage trim screw. Replace insert (15, Figure 3-15) if\n",
      "torque shall be 4.0 pound-inch minimum when\n",
      "breakaway torque is below limit.\n",
      "removing bypass valve (11). Replace insert (9)\n",
      "if breakaway torque is below limit.\n",
      "3.20\n",
      "REMOVAL OF NOZZLE CONTROL LIMIT\n",
      "--------------------------------------------------------------------------------\n",
      "üîé Chunk 2 (‡∏´‡∏ô‡πâ‡∏≤ 12):\n",
      "pull out spacers (38) from bore of linkage\n",
      "Exercise care not to overstretch the bellows\n",
      "bracket.\n",
      "while removing, as permanent deformation will\n",
      "(11)\n",
      "Carefully slide pin (40) out of the shaft of\n",
      "occur.\n",
      "sensor bellows (45); then remove screws (41).\n",
      "(13)\n",
      "Remove sensor bellows. After pin (Figure 3-9,\n",
      "Removal torque for screws (41) shall be 1.5\n",
      "40) has been removed, carefully remove bellows\n",
      "pound-inch minimum. Replace inserts (49) if\n",
      "by pulling on the flange end while pushing the\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Load index\n",
    "db = FAISS.load_local(\n",
    "    \"faiss_afterburner_index\",\n",
    "    embedding_model,\n",
    "    allow_dangerous_deserialization=True\n",
    ")\n",
    "\n",
    "\n",
    "query = \"‡∏Å‡∏≤‡∏£‡∏ñ‡∏≠‡∏î metering valve ‡∏ó‡∏≥‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£\"\n",
    "results = db.similarity_search(query, k=2)\n",
    "\n",
    "for i, r in enumerate(results, 1):\n",
    "    print(f\"üîé Chunk {i} (‡∏´‡∏ô‡πâ‡∏≤ {r.metadata['page']}):\") # which page of chunk\n",
    "    print(r.page_content[:500])\n",
    "    print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2ca0295",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_48272\\2897339608.py:5: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  llm = Ollama(model=\"mistral\")\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "\n",
    "llm = Ollama(model=\"mistral\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ec8df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")\n",
    "db = FAISS.load_local(\"faiss_afterburner_index\", embedding_model, allow_dangerous_deserialization=True)\n",
    "\n",
    "# Retrieval chain (good for untouch data)\n",
    "qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=db.as_retriever())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f59746f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ñ‡∏≠‡∏î Pilot Burner Regulator, ‡∏Ñ‡∏∏‡∏ì‡∏ï‡πâ‡∏≠‡∏á‡∏ó‡∏≥‡∏ï‡∏≤‡∏°‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô berikut:\n",
      "1. ‡∏ã‡πà‡∏≠‡∏°‡πÉ‡∏´‡πâ‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏™‡πà‡∏ß‡∏ô‡πÅ‡∏¢‡∏Å‡∏Å‡∏±‡∏ô‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡∏™‡∏£‡∏µ‡πÄ‡∏õ‡∏¥‡∏î-cleaner P-D-680, Type II or III.\n",
      "2. ‡∏ñ‡∏π‡∏Å‡πÑ‡∏õ‡∏Ñ‡∏∑‡∏ô‡πÅ‡∏•‡∏∞‡πÅ‡∏î‡∏Å‡∏ó‡∏∏‡∏Å‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡∏ö‡∏ô‡∏†‡∏≤‡∏û 3-1 ‡∏ï‡∏≤‡∏°‡∏ï‡∏±‡∏ß‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢:\n",
      "   a. ‡∏ô‡∏≥‡∏•‡πá‡∏≠‡∏Ñ‡πÑ‡∏ß‡∏£‡∏¥‡∏á‡∏≠‡∏≠‡∏Å‡πÅ‡∏•‡πâ‡∏ß‡∏à‡∏±‡∏î‡∏ó‡∏≥‡πÉ‡∏´‡∏°‡πà‡πÇ‡∏î‡∏¢‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡∏Å‡∏≤‡∏£‡∏Ç‡∏±‡∏î‡∏•‡∏≠‡∏Å‡πÑ‡∏ß‡∏£‡∏¥‡∏á\n",
      "   b. ‡∏ï‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏•‡πá‡∏≠‡∏Ñ‡πÑ‡∏ß‡∏£‡∏¥‡∏á‡∏≠‡∏≠‡∏Å\n",
      "3. ‡πÅ‡∏Å‡πâ‡∏õ‡∏∏‡πà‡∏°‡∏´‡∏•‡∏±‡∏Å (14, Figure 3-2) ‡∏à‡∏≤‡∏Å‡∏ä‡πà‡∏≠‡∏ó‡∏µ‡πà‡∏ö‡∏≥‡∏Å‡∏∞‡πÄ‡∏†‡∏≤\n",
      "   - ‡∏Ç‡∏ì‡∏∞‡∏ô‡∏µ‡πâ‡∏à‡∏∞‡πÄ‡∏´‡πá‡∏ô‡∏ß‡πà‡∏≤‡∏™‡πà‡∏ß‡∏ô‡∏•‡∏∂‡∏Å‡∏ô‡∏µ‡πâ‡∏°‡∏µ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡πÅ‡∏õ‡∏•‡∏á‡∏ä‡∏∑‡πà‡∏≠ 14\n",
      "4. ‡∏ñ‡∏π‡∏Å‡πÑ‡∏õ‡∏Ñ‡∏∑‡∏ô‡πÅ‡∏•‡πâ‡∏ß‡∏à‡∏±‡∏î‡∏ó‡∏≥‡∏†‡∏≤‡∏û 3-5\n",
      "   a. ‡∏ô‡∏≥‡∏£‡∏≠‡πÄ‡∏ï‡∏≠‡∏£‡πå (2, Figure 3-5) ‡∏≠‡∏≠‡∏Å\n",
      "   b. ‡∏´‡∏•‡∏µ‡∏Å‡∏ö‡∏ß‡∏°‡∏™‡πà‡∏ß‡∏ô‡∏£‡∏≠‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡πÄ‡∏ã‡πá‡∏Å‡∏ä‡∏±‡∏Å‡∏ô‡∏±‡πâ‡∏ô, ‡πÅ‡∏•‡πâ‡∏ß‡∏ñ‡∏π‡∏Å‡πÑ‡∏õ‡∏Ñ‡∏∑‡∏ô‡∏Ç‡πâ‡∏≤‡∏á‡∏ô‡∏≥‡∏£‡∏≠‡πÄ‡∏ï‡∏≠‡∏£‡πå\n",
      "5. ‡∏ï‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏ä‡∏∑‡πà‡∏≠ 1 ‡∏à‡∏≤‡∏Å‡πÄ‡∏ã‡πá‡∏Å‡∏ä‡∏±‡∏Å‡∏ô‡∏±‡πâ‡∏ô, ‡πÅ‡∏•‡πâ‡∏ß‡∏ñ‡∏π‡∏Å‡πÑ‡∏õ‡∏Ñ‡∏∑‡∏ô‡∏Ç‡πâ‡∏≤‡∏á‡∏ô‡∏≥‡∏£‡∏≠‡πÄ‡∏ï‡∏≠‡∏£‡πå\n",
      "6. ‡∏ô‡∏≥‡πÄ‡∏ã‡πá‡∏Å‡∏ä‡∏±‡∏Å‡∏ô‡∏±‡πâ‡∏ô (1) ‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡∏ä‡πà‡∏≠‡∏ó‡∏µ‡πà‡∏ö‡∏≥‡∏Å‡∏∞‡πÄ‡∏†‡∏≤\n",
      "7. ‡∏ñ‡∏π‡∏Å‡πÑ‡∏õ‡∏Ñ‡∏∑‡∏ô‡πÅ‡∏•‡πâ‡∏ß‡∏à‡∏±‡∏î‡∏ó‡∏≥‡∏†‡∏≤‡∏û 3-1\n",
      "   a. ‡∏ô‡∏≥‡∏ã‡πâ‡∏≤‡∏¢ (2, Figure 3-1) ‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡∏ä‡πà‡∏≠‡∏ó‡∏µ‡πà‡∏ö‡∏≥‡∏Å‡∏∞‡πÄ‡∏†‡∏≤\n",
      "   b. ‡∏ô‡∏≥‡∏™‡πà‡∏ß‡∏ô‡∏ã‡πâ‡∏≤‡∏¢ (4) ‡πÅ‡∏•‡∏∞‡∏ú‡∏π‡∏Å‡∏õ‡∏±‡∏ç‡∏´‡∏≤ (5), ‡∏õ‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡πÅ‡∏Å‡πâ‡∏õ‡∏∏‡πà‡∏°‡∏´‡∏•‡∏±‡∏Å\n",
      "8. ‡∏ñ‡∏π‡∏Å‡πÑ‡∏õ‡∏Ñ‡∏∑‡∏ô‡πÅ‡∏•‡πâ‡∏ß‡∏à‡∏±‡∏î‡∏ó‡∏≥‡∏†‡∏≤‡∏û 3-2\n",
      "   a. ‡∏ï‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏ä‡πà‡∏≠‡∏ó‡∏µ‡πà‡∏ö‡∏≥‡∏Å‡∏∞‡πÄ‡∏†‡∏≤ (3) ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡∏Å‡∏±‡∏ô‡∏™‡∏∞‡∏î‡∏ß‡∏Å Puller, PN 21C3605G001; ‡πÅ‡∏•‡πâ‡∏ß‡πÄ‡∏•‡∏¥‡∏Å‡∏ã‡∏∂‡πà‡∏á\n",
      "   b. ‡∏ï‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏ä‡πà‡∏≠‡∏ó‡∏µ‡πà‡∏ö‡∏≥‡∏Å‡∏∞‡πÄ‡∏†‡∏≤ (7)\n",
      "9. ‡∏ñ‡∏π‡∏Å‡πÑ‡∏õ‡∏Ñ‡∏∑‡∏ô‡πÅ‡∏•‡πâ‡∏ß‡∏à‡∏±‡∏î‡∏ó‡∏≥‡∏†‡∏≤‡∏û 3-5\n",
      "   a. ‡∏ô‡∏≥‡∏™‡πà‡∏ß‡∏ô‡∏ã‡πâ‡∏≤‡∏¢ (2, Figure 3-5) ‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡∏ä‡πà‡∏≠‡∏ó‡∏µ‡πà‡∏ö‡∏≥‡∏Å‡∏∞‡πÄ‡∏†‡∏≤\n",
      "   b. ‡∏´‡∏•‡∏µ‡∏Å‡∏ö‡∏ß‡∏°‡∏™‡πà‡∏ß‡∏ô‡∏£‡∏≠‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡πÄ‡∏ã‡πá‡∏Å‡∏ä‡∏±‡∏Å‡∏ô‡∏±‡πâ‡∏ô, ‡πÅ‡∏•‡πâ‡∏ß‡∏ñ‡∏π‡∏Å‡πÑ‡∏õ‡∏Ñ‡∏∑‡∏ô‡∏Ç‡πâ‡∏≤‡∏á‡∏ô‡∏≥‡∏£‡∏≠‡πÄ‡∏ï‡∏≠‡∏£‡πå\n"
     ]
    }
   ],
   "source": [
    "question = \"‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ñ‡∏≠‡∏î pilot burner regulator ‡∏ï‡πâ‡∏≠‡∏á‡∏ó‡∏≥‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£\"\n",
    "\n",
    "response = qa_chain.run(\n",
    "    f\"\"\"‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏î‡πâ‡∏≤‡∏ô‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢ ‡∏ä‡πà‡∏ß‡∏¢‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö:\n",
    "\\\"{question}\\\"\"\"\"\n",
    ")\n",
    "\n",
    "print(response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
